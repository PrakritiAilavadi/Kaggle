{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# RAPIDS cuML TfidfVectorizer and KNN to find similar Text and Images\nIn this notebook we use RAPIDS cuML's TfidfVectorizer and cuML's KNN to find items with similar titles and items with similar images. First we use RAPIDS cuML TfidfVectorizer to extract text embeddings of each item's title and then compare the embeddings using RAPIDS cuML KNN. Next we extract image embeddings of each item with EffNetB0 and compare them using RAPIDS cuML KNN.[](http://)","metadata":{}},{"cell_type":"markdown","source":"## Load Libraries","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport cv2, matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow.keras.applications import EfficientNetB0\nprint('TF',tf.__version__)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"TF 2.4.1\n","output_type":"stream"}]},{"cell_type":"code","source":"# RESTRICT TENSORFLOW TO 12GB OF GPU RAM\n# SO THAT WE HAVE GPU RAM FOR RAPIDS CUML KNN\nLIMIT = 12\ngpus = tf.config.experimental.list_physical_devices('GPU')\nif gpus:\n  try:\n    tf.config.experimental.set_virtual_device_configuration(\n        gpus[0],\n        [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024*LIMIT)])\n    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n  except RuntimeError as e:\n    print(e)\nprint('Restrict TensorFlow to max %iGB GPU RAM'%LIMIT)\nprint('so RAPIDS can use %iGB GPU RAM'%(16-LIMIT))","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"1 Physical GPUs, 1 Logical GPUs\nRestrict TensorFlow to max 12GB GPU RAM\nso RAPIDS can use 4GB GPU RAM\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Load Train Data\nIn this competition, we have items with an image and title. For the train data, the column `label_group` indicates the ground truth of which items are similar. We need to build a model that finds these similar images based on their image and title's text. In this notebook we explore some tools to help us.","metadata":{}},{"cell_type":"code","source":"train_df = pd.read_csv('../input/shopee-product-matching/train.csv')\nprint('train shape is', train_df.shape )\ntrain_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# let's see the number of unique label groups we have\ntrain_df['label_group'].nunique() \nprint(\"Number of unique groups are {} out of total records of {}\".format(train_df['label_group'].nunique(), len(train_df)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This means on an average a group would contain 3-4 items","metadata":{}},{"cell_type":"code","source":"train_df.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Dataset is clean, no null values in the dataset","metadata":{}},{"cell_type":"markdown","source":"## Displaying Random Images from Training Dataset ","metadata":{}},{"cell_type":"code","source":"BASE = '../input/shopee-product-matching/train_images/'\n\ndef display_image(train_df, rows, cols, path=BASE):\n    \n    for i in range(rows):\n        plt.figure(figsize=(20,5))\n        for j in range(cols):\n            row = np.random.randint(0, len(train_df)) # picking a random row\n            image_hash = train_df.iloc[row, 1]\n            image_decoded = cv2.imread(path + image_hash)\n            title = train_df.iloc[row, 3]\n            \n            text_ordering = \"\"\n            for i,ch in enumerate(title):\n                text_ordering += ch\n                if (i!=0) & (i%20 == 0):\n                    text_ordering += '\\n'\n                    \n            ## plot it out!\n            plt.subplot(1,cols,j+1) # subplot takes (rows, columns, nth plot)\n            plt.title(text_ordering)\n            plt.axis(\"off\")\n            plt.imshow(image_decoded)\n            \n    \n    plt.show()\n\n\ndisplay_image(train_df,4,6)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Displaying some Group items","metadata":{}},{"cell_type":"code","source":"groups = train_df.label_group.value_counts()\nplt.figure(figsize=(20,5))\nplt.bar(groups.index.values[:50].astype(str), groups.values[:50])\nplt.xticks(rotation = 50)\nplt.xlabel(\"Group Label\")\nplt.ylabel(\"Count of number of Items in the group\")\nplt.title(\"Top 50 Groups according to the frequency of the number of items in them\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for k in range(5):\n    print(\"#\"*40)\n    print(\"### Group {} with label: {}\".format(k+1, groups.index.values[k].astype(str)))\n    print(\"#\"*40)\n    Kth_df = train_df.loc[train_df.label_group == groups.index[k]]\n    display_image(Kth_df, 2, 4)\n    print(\"\\n\\n\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Finding Similar Titles","metadata":{}},{"cell_type":"code","source":"!pip install cuml","metadata":{"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: cuml in /opt/conda/lib/python3.7/site-packages (0.16.0)\nRequirement already satisfied: numba in /opt/conda/lib/python3.7/site-packages (from cuml) (0.52.0)\nRequirement already satisfied: cython in /opt/conda/lib/python3.7/site-packages (from cuml) (0.29.21)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from numba->cuml) (49.6.0.post20201009)\nRequirement already satisfied: llvmlite<0.36,>=0.35.0 in /opt/conda/lib/python3.7/site-packages (from numba->cuml) (0.35.0)\nRequirement already satisfied: numpy>=1.15 in /opt/conda/lib/python3.7/site-packages (from numba->cuml) (1.19.5)\n","output_type":"stream"}]},{"cell_type":"code","source":"import cuml, cudf, cupy\nfrom cuml.feature_extraction.text import TfidfVectorizer\nfrom cuml.neighbors import NearestNeighbors\nprint(\"RAPIDS CuML version: \", cuml.__version__)","metadata":{"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"RAPIDS CuML version:  0.16.0\n","output_type":"stream"}]},{"cell_type":"code","source":"train_df_gpu = pd.read_csv(\"../input/shopee-product-matching/train.csv\")\nprint(\"Shape of dataset: \", train_df_gpu.shape)\ntrain_df_gpu.head()","metadata":{"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Shape of dataset:  (34250, 5)\n","output_type":"stream"},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"         posting_id                                 image       image_phash  \\\n0   train_129225211  0000a68812bc7e98c42888dfb1c07da0.jpg  94974f937d4c2433   \n1  train_3386243561  00039780dfc94d01db8676fe789ecd05.jpg  af3f9460c2838f0f   \n2  train_2288590299  000a190fdd715a2a36faed16e2c65df7.jpg  b94cb00ed3e50f78   \n3  train_2406599165  00117e4fc239b1b641ff08340b429633.jpg  8514fc58eafea283   \n4  train_3369186413  00136d1cf4edede0203f32f05f660588.jpg  a6f319f924ad708c   \n\n                                               title  label_group  \n0                          Paper Bag Victoria Secret    249114794  \n1  Double Tape 3M VHB 12 mm x 4,5 m ORIGINAL / DO...   2937985045  \n2        Maling TTS Canned Pork Luncheon Meat 397 gr   2395904891  \n3  Daster Batik Lengan pendek - Motif Acak / Camp...   4093212188  \n4                  Nescafe \\xc3\\x89clair Latte 220ml   3648931069  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>posting_id</th>\n      <th>image</th>\n      <th>image_phash</th>\n      <th>title</th>\n      <th>label_group</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>train_129225211</td>\n      <td>0000a68812bc7e98c42888dfb1c07da0.jpg</td>\n      <td>94974f937d4c2433</td>\n      <td>Paper Bag Victoria Secret</td>\n      <td>249114794</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>train_3386243561</td>\n      <td>00039780dfc94d01db8676fe789ecd05.jpg</td>\n      <td>af3f9460c2838f0f</td>\n      <td>Double Tape 3M VHB 12 mm x 4,5 m ORIGINAL / DO...</td>\n      <td>2937985045</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>train_2288590299</td>\n      <td>000a190fdd715a2a36faed16e2c65df7.jpg</td>\n      <td>b94cb00ed3e50f78</td>\n      <td>Maling TTS Canned Pork Luncheon Meat 397 gr</td>\n      <td>2395904891</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>train_2406599165</td>\n      <td>00117e4fc239b1b641ff08340b429633.jpg</td>\n      <td>8514fc58eafea283</td>\n      <td>Daster Batik Lengan pendek - Motif Acak / Camp...</td>\n      <td>4093212188</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>train_3369186413</td>\n      <td>00136d1cf4edede0203f32f05f660588.jpg</td>\n      <td>a6f319f924ad708c</td>\n      <td>Nescafe \\xc3\\x89clair Latte 220ml</td>\n      <td>3648931069</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"### Extracting Text Embeddings using TfidfVectorizor","metadata":{}},{"cell_type":"code","source":"model = TfidfVectorizer(stop_words = 'english', binary=True)","metadata":{"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}