{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# RAPIDS cuML TfidfVectorizer and KNN to find similar Text and Images\nIn this notebook we use RAPIDS cuML's TfidfVectorizer and cuML's KNN to find items with similar titles and items with similar images. First we use RAPIDS cuML TfidfVectorizer to extract text embeddings of each item's title and then compare the embeddings using RAPIDS cuML KNN. Next we extract image embeddings of each item with EffNetB0 and compare them using RAPIDS cuML KNN.[](http://)","metadata":{}},{"cell_type":"markdown","source":"## Load Libraries","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport cv2, matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow.keras.applications import EfficientNetB0\nprint('TF',tf.__version__)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"TF 2.4.1\n","output_type":"stream"}]},{"cell_type":"code","source":"# RESTRICT TENSORFLOW TO 12GB OF GPU RAM\n# SO THAT WE HAVE GPU RAM FOR RAPIDS CUML KNN\nLIMIT = 12\ngpus = tf.config.experimental.list_physical_devices('GPU')\nif gpus:\n  try:\n    tf.config.experimental.set_virtual_device_configuration(\n        gpus[0],\n        [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024*LIMIT)])\n    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n  except RuntimeError as e:\n    print(e)\nprint('Restrict TensorFlow to max %iGB GPU RAM'%LIMIT)\nprint('so RAPIDS can use %iGB GPU RAM'%(16-LIMIT))","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"1 Physical GPUs, 1 Logical GPUs\nRestrict TensorFlow to max 12GB GPU RAM\nso RAPIDS can use 4GB GPU RAM\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Load Train Data\nIn this competition, we have items with an image and title. For the train data, the column `label_group` indicates the ground truth of which items are similar. We need to build a model that finds these similar images based on their image and title's text. In this notebook we explore some tools to help us.","metadata":{}},{"cell_type":"code","source":"train_df = pd.read_csv('../input/shopee-product-matching/train.csv')\nprint('train shape is', train_df.shape )\ntrain_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# let's see the number of unique label groups we have\ntrain_df['label_group'].nunique() \nprint(\"Number of unique groups are {} out of total records of {}\".format(train_df['label_group'].nunique(), len(train_df)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This means on an average a group would contain 3-4 items","metadata":{}},{"cell_type":"code","source":"train_df.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Dataset is clean, no null values in the dataset","metadata":{}},{"cell_type":"markdown","source":"## Displaying Random Images from Training Dataset ","metadata":{}},{"cell_type":"code","source":"BASE = '../input/shopee-product-matching/train_images/'\n\ndef display_image(train_df, rows, cols, path=BASE):\n    \n    for i in range(rows):\n        plt.figure(figsize=(20,5))\n        for j in range(cols):\n            row = np.random.randint(0, len(train_df)) # picking a random row\n            image_hash = train_df.iloc[row, 1]\n            image_decoded = cv2.imread(path + image_hash)\n            title = train_df.iloc[row, 3]\n            \n            text_ordering = \"\"\n            for i,ch in enumerate(title):\n                text_ordering += ch\n                if (i!=0) & (i%20 == 0):\n                    text_ordering += '\\n'\n                    \n            ## plot it out!\n            plt.subplot(1,cols,j+1) # subplot takes (rows, columns, nth plot)\n            plt.title(text_ordering)\n            plt.axis(\"off\")\n            plt.imshow(image_decoded)\n            \n    \n    plt.show()\n\n\ndisplay_image(train_df,4,6)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Displaying some Group items","metadata":{}},{"cell_type":"code","source":"groups = train_df.label_group.value_counts()\nplt.figure(figsize=(20,5))\nplt.bar(groups.index.values[:50].astype(str), groups.values[:50])\nplt.xticks(rotation = 50)\nplt.xlabel(\"Group Label\")\nplt.ylabel(\"Count of number of Items in the group\")\nplt.title(\"Top 50 Groups according to the frequency of the number of items in them\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for k in range(5):\n    print(\"#\"*40)\n    print(\"### Group {} with label: {}\".format(k+1, groups.index.values[k].astype(str)))\n    print(\"#\"*40)\n    Kth_df = train_df.loc[train_df.label_group == groups.index[k]]\n    display_image(Kth_df, 2, 4)\n    print(\"\\n\\n\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Finding Similar Titles","metadata":{}},{"cell_type":"code","source":"!pip install cuml","metadata":{"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: cuml in /opt/conda/lib/python3.7/site-packages (0.16.0)\nRequirement already satisfied: numba in /opt/conda/lib/python3.7/site-packages (from cuml) (0.52.0)\nRequirement already satisfied: cython in /opt/conda/lib/python3.7/site-packages (from cuml) (0.29.21)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from numba->cuml) (49.6.0.post20201009)\nRequirement already satisfied: llvmlite<0.36,>=0.35.0 in /opt/conda/lib/python3.7/site-packages (from numba->cuml) (0.35.0)\nRequirement already satisfied: numpy>=1.15 in /opt/conda/lib/python3.7/site-packages (from numba->cuml) (1.19.5)\n","output_type":"stream"}]},{"cell_type":"code","source":"import cuml, cudf, cupy\nfrom cuml.feature_extraction.text import TfidfVectorizer\nfrom cuml.neighbors import NearestNeighbors\nprint(\"RAPIDS CuML version: \", cuml.__version__)","metadata":{"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"RAPIDS CuML version:  0.16.0\n","output_type":"stream"}]},{"cell_type":"code","source":"# LOAD Training Data into GPU using CUDF!!!\ntrain_df_gpu = cudf.read_csv(\"../input/shopee-product-matching/train.csv\")\nprint(\"Shape of dataset: \", train_df_gpu.shape)\ntrain_df_gpu.head()","metadata":{"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"Shape of dataset:  (34250, 5)\n","output_type":"stream"},{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"         posting_id                                 image       image_phash  \\\n0   train_129225211  0000a68812bc7e98c42888dfb1c07da0.jpg  94974f937d4c2433   \n1  train_3386243561  00039780dfc94d01db8676fe789ecd05.jpg  af3f9460c2838f0f   \n2  train_2288590299  000a190fdd715a2a36faed16e2c65df7.jpg  b94cb00ed3e50f78   \n3  train_2406599165  00117e4fc239b1b641ff08340b429633.jpg  8514fc58eafea283   \n4  train_3369186413  00136d1cf4edede0203f32f05f660588.jpg  a6f319f924ad708c   \n\n                                               title  label_group  \n0                          Paper Bag Victoria Secret    249114794  \n1  Double Tape 3M VHB 12 mm x 4,5 m ORIGINAL / DO...   2937985045  \n2        Maling TTS Canned Pork Luncheon Meat 397 gr   2395904891  \n3  Daster Batik Lengan pendek - Motif Acak / Camp...   4093212188  \n4                  Nescafe \\xc3\\x89clair Latte 220ml   3648931069  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>posting_id</th>\n      <th>image</th>\n      <th>image_phash</th>\n      <th>title</th>\n      <th>label_group</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>train_129225211</td>\n      <td>0000a68812bc7e98c42888dfb1c07da0.jpg</td>\n      <td>94974f937d4c2433</td>\n      <td>Paper Bag Victoria Secret</td>\n      <td>249114794</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>train_3386243561</td>\n      <td>00039780dfc94d01db8676fe789ecd05.jpg</td>\n      <td>af3f9460c2838f0f</td>\n      <td>Double Tape 3M VHB 12 mm x 4,5 m ORIGINAL / DO...</td>\n      <td>2937985045</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>train_2288590299</td>\n      <td>000a190fdd715a2a36faed16e2c65df7.jpg</td>\n      <td>b94cb00ed3e50f78</td>\n      <td>Maling TTS Canned Pork Luncheon Meat 397 gr</td>\n      <td>2395904891</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>train_2406599165</td>\n      <td>00117e4fc239b1b641ff08340b429633.jpg</td>\n      <td>8514fc58eafea283</td>\n      <td>Daster Batik Lengan pendek - Motif Acak / Camp...</td>\n      <td>4093212188</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>train_3369186413</td>\n      <td>00136d1cf4edede0203f32f05f660588.jpg</td>\n      <td>a6f319f924ad708c</td>\n      <td>Nescafe \\xc3\\x89clair Latte 220ml</td>\n      <td>3648931069</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"### Extracting Text Embeddings using TfidfVectorizor","metadata":{}},{"cell_type":"code","source":"model = TfidfVectorizer(stop_words = 'english', binary=True)\ntext_embeddings = model.fit_transform(train_df_gpu.title).toarray()\nprint(\"Shape of text embeddings: \", text_embeddings.shape)","metadata":{"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"Shape of text embeddings:  (34250, 24939)\n","output_type":"stream"}]},{"cell_type":"code","source":"text_embeddings ## Sparse Matrix","metadata":{"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"array([[0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       ...,\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"},"metadata":{}}]},{"cell_type":"markdown","source":"### Classifying Similar Titles using KNN","metadata":{}},{"cell_type":"code","source":"knn_model = NearestNeighbors(n_neighbors=50)\nknn_model.fit(text_embeddings)\ndistances, indices = knn_model.kneighbors(text_embeddings)","metadata":{"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"print(\"Distances: \", distances, \"\\n\")\nprint(\"Indices: \", indices)","metadata":{"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"Distances:  [[0.         0.         1.0958833  ... 1.2939385  1.2949737  1.2954024 ]\n [0.         0.9047     0.9397362  ... 1.2889568  1.2915127  1.2919577 ]\n [0.         0.8221763  1.280804   ... 1.3698959  1.3700792  1.3700906 ]\n ...\n [0.         0.8017645  0.846956   ... 1.2954924  1.2956679  1.2960013 ]\n [0.         0.81143415 0.82256556 ... 1.327445   1.3280029  1.328192  ]\n [0.         0.8836633  1.1210921  ... 1.2967644  1.2970171  1.3020754 ]] \n\nIndices:  [[    0 33161  9219 ... 14456  7147  7433]\n [    1 18683 23593 ... 21923   666 12203]\n [    2 15668  6353 ... 21075 11305  7202]\n ...\n [34247 18379 13116 ... 33794 10320 29336]\n [34248 13887 20813 ... 22306  5554 14443]\n [34249 33792 13152 ... 17742 30214 15478]]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Gives the indices of similar titles","metadata":{}},{"cell_type":"code","source":"## Printing first 10 items of each of the 5 groups of titles obtained by tuning the KNN model on text embeddings\n\nfor k in range(5):\n    print(train_df_gpu.loc[cupy.asnumpy(indices[k,:10]), ['title', 'label_group']])\n    print(\"\\n\")\n    print(\"\\n\")","metadata":{"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"                                                   title  label_group\n0                              Paper Bag Victoria Secret    249114794\n33161                          PAPER BAG VICTORIA SECRET    249114794\n9219                             PAPER BAG THE BODY SHOP    471581622\n25386  READY! GRATIS ISI ULANG! Pengharum parfum mobi...    866425052\n31159                      Paper Bag The Body Shop Small    471581622\n8469   b\"victoria iria Goat's Milk Hand Body Lotion 2...    865318054\n2676           Paper Bag Tas Kertas Polos Ukuran 18x5x22    982607408\n30518                           VELROSE SECRET FACE MASK   2992234715\n4156   Dengan Paper Bag TABITA EXCLUSIVE ORIGINAL KEM...   2591192196\n28498              WARDAH WHITE SECRET FACIAL WASH 100ml   1952691729\n\n\n\n\n                                                   title  label_group\n1      Double Tape 3M VHB 12 mm x 4,5 m ORIGINAL / DO...   2937985045\n18683  Double Tape VHB 3M ORIGINAL 12mm x 4.5mm Busa ...   2937985045\n23593  Double Tape 3M 4900 VHB 24 mm x 4.5m tebal 1.1...   2819310070\n25199  3M VHB 12mm x 4.5m Double Tape Foam Merah Otom...   2819310070\n194    3M VHB Double Tape Automotive 4900 tebal 1.1 m...   2819310070\n469    3M VHB Double Tape Automotive 4900 tebal 1.1 m...   2819310070\n4774   3M 1600 T Double Tape PE Foam tebal: 1.0 mm, s...    475342649\n21790  DOUBLE TAPE BUSA 3M Pe Foam Tape 24mm x 4M ORI...    475342649\n19262  DOUBLE TAPE BUSA 3M Pe Foam Tape 24mm x 4M ORI...    475342649\n10444  DOUBLE TAPE BUSA 3M Pe Foam Tape 24mm x 4M ORI...    475342649\n\n\n\n\n                                                   title  label_group\n2            Maling TTS Canned Pork Luncheon Meat 397 gr   2395904891\n15668            Maling Ham Pork Luncheon Meat TTS 397gr   2395904891\n6353                    MEAT GRINDER / PENGGILING DAGING   3760480756\n25580                        Samcan babi atau Pork Belly   2572087261\n205                               M031 Alarm anti maling   1943235893\n5294   Life Cat Pounch 85gr Makanan Basah Kucing No Pork   1300007930\n22085     Gembok Alarm Ring Panjang / Gembok Anti Maling   3940507552\n17339  Gembok Alarm Ring Panjang / Gembok anti maling...   3940507552\n33978  b\"Pigeon Toddy Palm's Seed in Syrup Canned- Lo...   1890922178\n1943   1KG DAGING BABI HAS DALAM ( FRESH TENDERLOIN M...    567923746\n\n\n\n\n                                                   title  label_group\n3      Daster Batik Lengan pendek - Motif Acak / Camp...   4093212188\n28878  Daster Batik Lengan pendek - Motif Acak / Camp...   3150867956\n32290  Daster Batik Lengan pendek - Motif Acak / Camp...   2453599242\n2522   Daster Batik Lengan pendek - Motif Acak / Camp...    264184112\n20105  Daster Batik Bali Lengan pendek - Motif Acak /...   3150867956\n27637  Daster payung klok motif acak/campur leher kan...   2560881468\n27812  Daster Karakter - Leher Kancing (DPT001-00) Bu...   1773396944\n22183  Daster Payung Bali JUMBO XXL, Motif Acak / Cam...   2560881468\n18753  DASTER KARAKTER lengan pendek/motif campur kat...   1773396944\n4981                Daster Batik Anak Tanpa Lengan putih   1339781222\n\n\n\n\n                                                   title  label_group\n4                      Nescafe \\xc3\\x89clair Latte 220ml   3648931069\n18449                    Nescafe Eclair Latte Pet 220 Ml   3648931069\n252                                      Nescafe classic   3030935442\n3863                               Torabika Creamy Latte   2111685755\n11352                              Torabika creamy latte   2111685755\n2900                            Kopi Nescafe Classic 2gr   3030935442\n9438                   Refill Kopi Nescafe Classic 100gr      9958453\n8890                   Refill Kopi Nescafe Classic 100gr      9958453\n27836  BIOAQUA Aloe Vera Soothing Moisture 92% Pelemb...   3115028838\n29452                    Kopi NESCAFE Classic sachet 2gr   3030935442\n\n\n\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Finding Similar Images","metadata":{}},{"cell_type":"markdown","source":"### Extracting Image Embeddings using EffNetB0","metadata":{}},{"cell_type":"code","source":"BASE = \"../input/shopee-product-matching/train.csv\"\n\nclass DataGenerator(tf.keras.utils.Sequence):\n    'Generates data for Keras'\n    def __init__(self, df, img_size=256, batch_size=32, path=BASE): \n        self.df = df\n        self.img_size = img_size\n        self.batch_size = batch_size\n        self.path = path\n        self.indexes = np.arange( len(self.df) )\n        \n    def __len__(self):\n        'Denotes the number of batches per epoch'\n        ct = len(self.df) // self.batch_size\n        ct += int(( (len(self.df)) % self.batch_size)!=0)\n        return ct\n\n    def __getitem__(self, index):\n        'Generate one batch of data'\n        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n        X = self.__data_generation(indexes)\n        return X\n            \n    def __data_generation(self, indexes):\n        'Generates data containing batch_size samples' \n        X = np.zeros((len(indexes),self.img_size,self.img_size,3),dtype='float32')\n        df = self.df.iloc[indexes]\n        for i,(index,row) in enumerate(df.iterrows()):\n            img = cv2.imread(self.path+row.image)\n            X[i,] = cv2.resize(img,(self.img_size,self.img_size)) #/128.0 - 1.0\n        return X","metadata":{"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"model = EfficientNetB0(weights='imagenet')","metadata":{},"execution_count":null,"outputs":[]}]}